{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0028a4-1ad8-48c9-8c1c-425eed3a7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class UAVArgs:\n",
    "    # UAV params\n",
    "    sensor_res = 90.0 # Size of each segment\n",
    "    sense_sector_count = int(360.0/sensor_res)\n",
    "    sensor_range = None\n",
    "    dmax = 1.0\n",
    "\n",
    "class ForestArgs:\n",
    "    # Forest Domain params\n",
    "    length = 100.0 # length of the forest environment(along x-axis)\n",
    "    width = 100.0 # Width of the forest environment(along y-axis)\n",
    "    agent_count = 1 # Number of agents in the system.\n",
    "    fire_count = 1 # Number of fire targets in the system.\n",
    "    max_steps = 10 # Number of steps in an episode.\n",
    "    epsilon = 0.3 # Exploration factor (e-greedy)\n",
    "\n",
    "uavArgs = UAVArgs()\n",
    "forestArgs = ForestArgs()\n",
    "agents = [Agent(idx, 0.0, 0.0, 0, uavArgs) for idx in range(forestArgs.agent_count)] # Configure the agents. SpawnAgents()\n",
    "fires = [Fire(idx, 1.0, 1.0, 5, \"tight\") for idx in range(forestArgs.fire_count)] # Configure the fires (especially the position and values). SpawnFires()\n",
    "env = ForestDomain(forestArgs, agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9e7ba2-6de8-4238-ac9f-1b4a064c625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Rover_Canvas.rover_domain_python import *\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313a1ac-e60a-4c71-855d-d0cfb9365f01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "actionspace = {forward, left, backward, right, wait}\n",
    "sensorspace = {front, left, right, on}\n",
    "class Agent:\n",
    "    def __init__(self, agent_id, xpos, ypos, theta, args):\n",
    "        self.agent_id = args.agent_id\n",
    "        self.location = np.array([xpos, ypos, theta]) # (x, y, theta) - Position world coordinates of the Agent with orientation angle wrt North.\n",
    "        self.sense_theta = 90 # theta angle for each state.\n",
    "        self.policy = [] # policy the agent learns for a trial.\n",
    "        self.history = [] # history[timestamp] = (x,y) - coordinates of agent at given timestamp.\n",
    "        self.observations = np.zeros()\n",
    "        self.Qtable = [] # This will store a tuple of state(L/F/R , action)\n",
    "\n",
    "    def reset(self):\n",
    "        self.position = (0,0)\n",
    "        self.forward_direction = 0\n",
    "        self.velocity = (0.0, 0.0)\n",
    "        self.policy = []\n",
    "        self.history = []\n",
    "\n",
    "    def get_state(self, direction):\n",
    "        diff = direction - self.forward_direction\n",
    "        if diff >= -self.sense_theta/2.0f and diff <= self.sense_theta/2.0f :\n",
    "\n",
    "    def get_observation(self, ):\n",
    "    \n",
    "    def sense_fire():\n",
    "        \n",
    "\n",
    "    def sense_agents():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602032c-db82-4bb1-9ab8-243cdb8fe818",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Fire:\n",
    "    def __init__(self, fire_id, xpos, ypos, value, coupling):\n",
    "        self.poi_id = fire_id\n",
    "        self.loc = [xpos, ypos]\n",
    "        self.value = value\n",
    "        self.coupling = coupling # tight - needs minimum agents to start harvesting; loose - harvesting can be started by 1 agent.\n",
    "        self.observed = False\n",
    "        self.observer_distances = np.zeros(p[\"n_rovers\"])\n",
    "        self.quadrant = None\n",
    "        \n",
    "    def reset(self, fire_config):\n",
    "        self.loc[0] = poi_config[0]\n",
    "        self.loc[1] = poi_config[1]\n",
    "        self.value = poi_config[2]\n",
    "        self.coupling = poi_config[3]\n",
    "        self.observer_distances = np.zeros(p[\"n_rovers\"])\n",
    "        self.observed = False\n",
    "        \n",
    "    def update_observer_distances(self, rovers):\n",
    "        \"\"\"\n",
    "        Records the linear distances between rovers in the system and the POI for use in reward calculations\n",
    "        \"\"\"\n",
    "        for rov in rovers:\n",
    "            dist = get_linear_dist(rovers[rov].loc[0], rovers[rov].loc[1], self.loc[0], self.loc[1])\n",
    "            self.observer_distances[rovers[rov].rover_id] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a80d2-ba2f-4610-a622-50003c2ece44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports for the Forest Domain.\n",
    "import random, sys\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32937d3-c93d-4cf1-8cb6-ee275be4c381",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ForestDomain:\n",
    "    def __init__(self, args, agents, pois):\n",
    "        # World attributes\n",
    "        self.world_x = p[\"x_dim\"]\n",
    "        self.world_y = p[\"y_dim\"]\n",
    "        self.n_pois = p[\"n_poi\"]\n",
    "        self.n_rovers = p[\"n_rovers\"]\n",
    "        self.obs_radius = p[\"observation_radius\"]  # Maximum distance rovers can make observations of POI at\n",
    "        self.rover_poi_distances = [[] for i in range(self.n_pois)]  # Tracks rover distances to POI at each time step\n",
    "\n",
    "        # Rover Instances\n",
    "        self.rovers = {}  # Dictionary containing instances of rover objects\n",
    "        self.rover_configurations = [[] for _ in range(p[\"n_rovers\"])]\n",
    "\n",
    "        # POI Instances\n",
    "        self.pois = {}  # Dictionary containing instances of PoI objects\n",
    "        self.poi_configurations = [[] for _ in range(p[\"n_poi\"])]\n",
    "        \n",
    "    def reset(self, cf_id):\n",
    "        self.rover_poi_distances = [[] for i in range(self.n_pois)]\n",
    "        for rv in self.rovers:\n",
    "            self.rovers[rv].reset_rover(self.rover_configurations[self.rovers[rv].rover_id][cf_id])\n",
    "        for poi in self.pois:\n",
    "            self.pois[poi].reset_poi(self.poi_configurations[self.pois[poi].poi_id][cf_id])\n",
    "\n",
    "    def load_world(self):\n",
    "        \"\"\"\n",
    "        Load a rover domain from a saved csv file.\n",
    "        \"\"\"\n",
    "        # Initialize POI positions and values\n",
    "        self.load_poi_configuration()\n",
    "\n",
    "        # Initialize Rover Positions\n",
    "        self.load_rover_configuration()\n",
    "    \n",
    "    def load_poi_configuration(self):\n",
    "        \"\"\"\n",
    "        Load POI configuration from a CSV file\n",
    "        \"\"\"\n",
    "\n",
    "        for cf_id in range(p[\"n_configurations\"]):\n",
    "            csv_input = []\n",
    "            with open(f'./World_Config/POI_Config{cf_id}.csv') as csvfile:\n",
    "                csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    csv_input.append(row)\n",
    "\n",
    "            for poi_id in range(self.n_pois):\n",
    "                poi_x = float(csv_input[poi_id][0])\n",
    "                poi_y = float(csv_input[poi_id][1])\n",
    "                poi_val = float(csv_input[poi_id][2])\n",
    "                poi_coupling = float(csv_input[poi_id][3])\n",
    "                poi_hazard = float(csv_input[poi_id][4])\n",
    "\n",
    "                if cf_id == 0:\n",
    "                    self.pois[f'P{poi_id}'] = POI(poi_x, poi_y, poi_val, poi_coupling, poi_id)\n",
    "\n",
    "                self.poi_configurations[poi_id].append((poi_x, poi_y, poi_val, poi_coupling, poi_hazard))\n",
    "\n",
    "    def load_rover_configuration(self):\n",
    "        \"\"\"\n",
    "        Load Rover configuration from a saved csv file\n",
    "        \"\"\"\n",
    "\n",
    "        for cf_id in range(p[\"n_configurations\"]):\n",
    "            csv_input = []\n",
    "            with open(f'./World_Config/Rover_Config{cf_id}.csv') as csvfile:\n",
    "                csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "                for row in csv_reader:\n",
    "                    csv_input.append(row)\n",
    "\n",
    "            for rover_id in range(self.n_rovers):\n",
    "                rov_x = float(csv_input[rover_id][0])\n",
    "                rov_y = float(csv_input[rover_id][1])\n",
    "                rov_theta = float(csv_input[rover_id][2])\n",
    "\n",
    "                if cf_id == 0:\n",
    "                    self.rovers[f'R{rover_id}'] = Rover(rover_id, rov_x, rov_y, rov_theta)\n",
    "\n",
    "                self.rover_configurations[rover_id].append((rov_x, rov_y, rov_theta))\n",
    "\n",
    "    def calc_global(self):\n",
    "        \"\"\"\n",
    "        Calculate the global reward for the current state as the reward given by each POI.\n",
    "        \"\"\"\n",
    "        global_reward = np.zeros(self.n_pois)\n",
    "\n",
    "        for poi in self.pois:\n",
    "            observer_count = 0\n",
    "            rover_distances = copy.deepcopy(self.pois[poi].observer_distances)\n",
    "            rover_distances = np.sort(rover_distances)  # Arranges distances from least to greatest\n",
    "\n",
    "            for i in range(int(self.pois[poi].coupling)):\n",
    "                if rover_distances[i] < self.obs_radius:\n",
    "                    observer_count += 1\n",
    "\n",
    "            # Update global reward if POI is observed\n",
    "            if observer_count >= int(self.pois[poi].coupling):\n",
    "                summed_dist = sum(rover_distances[0:int(self.pois[poi].coupling)])\n",
    "                global_reward[self.pois[poi].poi_id] = self.pois[poi].value / (summed_dist/self.pois[poi].coupling)\n",
    "\n",
    "        return global_reward\n",
    "\n",
    "    def step():\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635a8f4-db23-43f4-9960-9f2f4baf5c2e",
   "metadata": {},
   "source": [
    "# Testing Zerb's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda92e7c-0df1-4618-97a7-1d03eff0562f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRoverDomain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRoverDomainCore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrover_domain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rover_domain\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRoverDomain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parameters \u001b[38;5;28;01mas\u001b[39;00m p\n",
      "File \u001b[1;32mD:\\Multiagent Systems\\Final Project\\MASProject\\RoverDomain\\RoverDomainCore\\rover_domain.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parameters \u001b[38;5;28;01mas\u001b[39;00m p\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRoverDomainCore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrover\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rover\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRoverDomainCore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m POI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'parameters'"
     ]
    }
   ],
   "source": [
    "from RoverDomain.RoverDomainCore.rover_domain import RoverDomain\n",
    "import numpy as np\n",
    "from RoverDomain.parameters import parameters as p\n",
    "from global_functions import create_csv_file, save_best_policies\n",
    "from Visualizer.turtle_visualizer import run_rover_visualizer\n",
    "from Visualizer.visualizer import run_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d36058-2b80-4f7f-8266-bee2294a44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rover_global():\n",
    "    \"\"\"\n",
    "    Train rovers in the classic rover domain using the global reward\n",
    "    \"\"\"\n",
    "    # World Setup\n",
    "    rd = RoverDomain()\n",
    "    rd.load_world()\n",
    "    \n",
    "    # Q-learning\n",
    "    # Take the step\n",
    "    # Get observations(s') and rewards r\n",
    "    # Update Q values for each agent according to action each took.\n",
    "    # decay epsilon\n",
    "    epsilon = p[\"epsilon_q\"]\n",
    "    decay = p[\"epsilon_decay_factor\"]\n",
    "    poi_rewards = np.zeros((p[\"n_poi\"], p[\"steps\"]))\n",
    "    for step in range(p[\"steps\"]):\n",
    "        rover_actions = []\n",
    "        for rv in rd.rovers:\n",
    "            direction, angle = e_greedy(epsilon, rv)\n",
    "            action_bracket = int(angle / rv.sensor_res)\n",
    "            if action_bracket > rv.n_brackets-1:\n",
    "                    action_bracket -= n_brackets\n",
    "            rv.action_quad = action_bracket\n",
    "            rover_actions.append(direction)\n",
    "            \n",
    "        step_rewards = rv.step(rover_actions)\n",
    "        g_reward = sum(step_rewards) - 1 # -1 for taking a step.\n",
    "        # Assign the agents with thier local rewards.\n",
    "        for rv in rd.rovers:\n",
    "            # Using G(z) for local rewards and Q-value updates.\n",
    "            rv.reward = g_reward \n",
    "            # Call Update Qvalues\n",
    "            rv.update_Qvalues()\n",
    "        \n",
    "        epsilon *= decay\n",
    "    \n",
    "\n",
    "def e_greedy(epsilon, rov):\n",
    "    if np.random.rand() < epsilon:\n",
    "        # We explore\n",
    "        direction = [np.random.rand(), np.random.rand()]\n",
    "        angle = get_angle(direction[0], direction[1], p[\"x_dim\"]/2, p[\"y_dim\"]/2)\n",
    "        return direction, angle\n",
    "    else:\n",
    "        # We exploit\n",
    "        q_values = [rov.get_Qvalue(rov.observations, action) for action in range(rov.n_brackets)]\n",
    "        max_Qvalue = np.max(q_values)\n",
    "        best_action = rov.n_brackets[np.argmax(q_values)]\n",
    "        \n",
    "        direction = rov.action_space[best_action]        \n",
    "        angle = get_angle(direction[0], direction[1], p[\"x_dim\"]/2, p[\"y_dim\"]/2)\n",
    "        return direction, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d556f-7c1b-4729-9c3d-a4304ca4e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rover_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42359a9-7ff3-4875-a80e-6787556661b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
